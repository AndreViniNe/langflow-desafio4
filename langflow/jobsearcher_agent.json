{"id":"853b597d-5d3b-4994-bcb6-48bc20e9821e","data":{"nodes":[{"id":"ToolCallingAgent-XKkdS","type":"genericNode","position":{"x":1765.7668558965586,"y":414.9799400011884},"data":{"type":"ToolCallingAgent","node":{"template":{"_type":"Component","chat_history":{"trace_as_metadata":true,"list":true,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"chat_history","value":"","display_name":"Chat History","advanced":true,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"llm":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"name":"llm","value":"","display_name":"Language Model","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"tools":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"name":"tools","value":"","display_name":"Tools","advanced":false,"input_types":["Tool","BaseTool"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, List\n\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import HandleInput, DataInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Compile User Profile\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"handle_parsing_errors":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"handle_parsing_errors","value":true,"display_name":"Handle Parse Errors","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"max_iterations":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_iterations","value":20,"display_name":"Max Iterations","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput","load_from_db":false},"system_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_prompt","value":"","display_name":"System Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System prompt for the agent.","title_case":false,"type":"str","_input_type":"MultilineInput"},"user_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"user_prompt","value":"{input}","display_name":"Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"This prompt must contain 'input' key.","title_case":false,"type":"str","_input_type":"MultilineInput"},"verbose":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"verbose","value":true,"display_name":"Verbose","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Compile User Profile","icon":"LangChain","base_classes":["AgentExecutor","Message"],"display_name":"Tool Calling Agent","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["AgentExecutor"],"selected":"AgentExecutor","name":"agent","display_name":"Agent","method":"build_agent","value":"__UNDEFINED__","cache":true},{"types":["Message"],"selected":"Message","name":"response","display_name":"Response","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","tools","llm","system_prompt","user_prompt","chat_history"],"beta":true,"edited":true},"id":"ToolCallingAgent-XKkdS"},"selected":false,"width":384,"height":611,"dragging":false,"positionAbsolute":{"x":1765.7668558965586,"y":414.9799400011884}},{"id":"ChatInput-PESbG","type":"genericNode","position":{"x":-326.7663752215084,"y":100.05514702894459},"data":{"type":"ChatInput","node":{"template":{"_type":"Component","files":{"trace_as_metadata":true,"file_path":"","fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx","jpg","jpeg","png","bmp","image"],"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","title_case":false,"type":"file","_input_type":"FileInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\nfrom time import sleep\nfrom random import random\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n    \n        self.status = message\n        wait_api = round(random() * 10)\n        print(f\"WAITING {wait_api} SECONDS. BEFORE API CALLS!\")\n        sleep(wait_api)\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"Please, can you find jobs for the current users in table: user_infos that is not Processed! in status yet?\nENSURE user_id and user_name from Postgresql table public.user_infos to be passed along with the user information so the next process can use it.\nOUTPUT the user_id, user_name, job_preferences, linkedin_url, and the completee profile DETAIL\nIN YOUR RESPONSE IS MANDATORY TO INITIATE WITH user_name: <NAME-OF_USER got from postgres> and user_id: <id of the user got from postgres>","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"combobox":false,"required":false,"placeholder":"","show":true,"value":"User","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str","_input_type":"DropdownInput"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"User","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"should_store_message":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"should_store_message","display_name":"Store Messages","advanced":true,"dynamic":false,"info":"Store the message in the history.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message"],"display_name":"Chat Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","should_store_message","sender","sender_name","session_id","files"],"beta":false,"edited":true,"lf_version":"1.0.17"},"id":"ChatInput-PESbG"},"selected":false,"width":384,"height":298,"dragging":false,"positionAbsolute":{"x":-326.7663752215084,"y":100.05514702894459}},{"id":"Prompt-z1VCm","type":"genericNode","position":{"x":943.9672757965611,"y":113.14519037938547},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"You are a Internship Job Seeker based on a person resume suggests from at maximum 5 jobs that have most relevance with the user input\n\n1. Run this SQL Statement in Postgres to Get Users information: SELECT user_id, user_name, job_preferences, linkedin_url\nFROM public.user_infos\nwhere status is null;\nStore this information in response and initiate the response with like: (user_id:13, name:'Andre')\n2. If No User is returned Just send No Users Found Do Not RUN!\n3. Get each user id linkedin_url  and using the tool inkedin_profile_details get the user information + Add the user_id and name you got previously from SQL Statement in Postgres to Get Users information: \n4. OUTPUT the user_id, user_name, job_preferences, linkedin_url found in database, along with complete profile DETAIL WITH THE PROFILE DESCRIPTION!\n5. IN YOUR RESPONSE IS MANDATORY TO INITIATE WITH user_name: <NAME-OF_USER got from postgres> and user_id: <id of the user got from postgres>\n\n","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput","load_from_db":false}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":[]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-z1VCm","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":326,"dragging":false,"positionAbsolute":{"x":943.9672757965611,"y":113.14519037938547}},{"id":"OpenAIModel-Wo0Xn","type":"genericNode","position":{"x":1359.5332754398355,"y":1354.5430885878334},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"json_mode","value":false,"display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gpt-4o-mini","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"output_schema","value":{},"display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"seed","value":1,"display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"OpenAIModel-Wo0Xn","description":"Generates text using OpenAI LLMs.","display_name":"OpenAI"},"selected":false,"width":384,"height":601,"positionAbsolute":{"x":1359.5332754398355,"y":1354.5430885878334},"dragging":false},{"id":"postgresql_query-Yu6rj","type":"genericNode","position":{"x":-599.6725229608346,"y":930.3868352526597},"data":{"type":"postgresql_query","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional,Union\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.inputs import MessageTextInput, SecretStrInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.field_typing import Tool\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\nimport psycopg2  # PostgreSQL connect lib\n\n\nclass PostgreSQLQueryComponent(LCToolComponent):\n    display_name: str = \"PostgreSQL Query\"\n    description: str = \"Execute a query against a PostgreSQL database and return the results.\"\n    name = \"postgresql_query\"\n    icon = \"database\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"host\",\n            display_name=\"Host\",\n            info=\"PostgreSQL server address\",\n        ),\n        MessageTextInput(\n            name=\"user\",\n            display_name=\"User\",\n            info=\"Username for authentication\",\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Password\",\n            info=\"Password for authentication\",\n        ),\n        MessageTextInput(\n            name=\"database\",\n            display_name=\"Database\",\n            info=\"Database name\",\n        ),\n        MultilineInput(\n            name=\"query\",\n            display_name=\"Query\",\n            info=\"The SQL query to execute\",\n        ),\n    ]\n\n    class PostgreSQLQuerySchema(BaseModel):\n        query: str = Field(..., description=\"The SQL query to execute\")\n\n    def run_model(self) -> Union[Data, list[Data]]:\n        # Coletando os inputs\n        result = [\"A\", \"B\"]\n        data = [Data(data=row, text=str(row)) for row in result]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"postgresql_query\",\n            description=\"Executes a query against a PostgreSQL database. Input must include 'host', 'user', 'password', 'database', and 'query'.\",\n            func=self._execute_query,\n            args_schema=self.PostgreSQLQuerySchema,\n        )\n\n    def _execute_query(self, query: str) -> str:\n        connection = None  # Initialize connection to None\n        try:\n            connection = psycopg2.connect(\n                host=self.host,\n                user=self.user,\n                password=self.password,\n                database=self.database\n            )\n            cursor = connection.cursor()\n            cursor.execute(query)\n    \n            # Commit changes for INSERT/UPDATE/DELETE queries\n            connection.commit()\n    \n            # Check if the query is a SELECT statement\n            if query.strip().lower().startswith(\"select\"):\n                result = cursor.fetchall()\n                return \"\\n\".join([str(row) for row in result])\n            else:\n                return \"Query executed successfully!\"  # For INSERT/UPDATE/DELETE\n        except Exception as e:\n            return f\"Error executing query: {str(e)}\"\n        finally:\n            if cursor:\n                cursor.close()\n            if connection:\n                connection.close()\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"database":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"database","value":"postgres","display_name":"Database","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Database name","title_case":false,"type":"str","_input_type":"MessageTextInput"},"host":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"host","value":"langflow.cfm022gi4exh.us-east-1.rds.amazonaws.com","display_name":"Host","advanced":false,"input_types":["Message"],"dynamic":false,"info":"PostgreSQL server address","title_case":false,"type":"str","_input_type":"MessageTextInput"},"password":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"password","value":"","display_name":"Password","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Password for authentication","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"query":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"query","value":"","display_name":"Query","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The SQL query to execute","title_case":false,"type":"str","_input_type":"MultilineInput"},"user":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"user","value":"mestredosmagos","display_name":"User","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Username for authentication","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Execute a query against a PostgreSQL database and return the results.","icon":"database","base_classes":["Data","Tool"],"display_name":"PostgreSQL Query","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"api_run_model","display_name":"Data","method":"run_model","value":"__UNDEFINED__","cache":true},{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["host","user","password","database","query"],"beta":false,"edited":true,"lf_version":"1.0.17"},"id":"postgresql_query-Yu6rj"},"selected":true,"width":384,"height":717,"positionAbsolute":{"x":-599.6725229608346,"y":930.3868352526597},"dragging":false},{"id":"PythonCodeStructuredTool-3MIXn","type":"genericNode","position":{"x":275.89189417312423,"y":1003.9461727226117},"data":{"type":"PythonCodeStructuredTool","node":{"template":{"_type":"Component","_classes":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"_classes","value":"[]","display_name":"Classes","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"_functions":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"_functions","value":"{\"get_linkedin_profile_details\": {\"name\": \"get_linkedin_profile_details\", \"args\": [{\"name\": \"linkedin_profile_url\", \"annotation\": \"str\"}]}}","display_name":"Functions","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Get Linkedin Profile Details\"\n    description = \"Tool for linkedin profile data collection\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"linkedin\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"global_variables":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"name":"global_variables","value":"","display_name":"Global Variables","advanced":false,"input_types":["Data"],"dynamic":false,"info":"Enter the global variables or Create Data Component.","title_case":false,"type":"dict","_input_type":"HandleInput"},"return_direct":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"return_direct","value":true,"display_name":"Return Directly","advanced":false,"dynamic":false,"info":"Should the tool return the function output directly?","title_case":false,"type":"bool","_input_type":"BoolInput","load_from_db":false},"tool_code":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"def my_function(args):\n    pass","show":true,"name":"tool_code","value":"import requests\nimport json\n\n\ndef get_linkedin_profile_details(linkedin_profile_url: str):\n    \"\"\"\n    Arguments:\n    ------------\n    linkedin_profile_url: linkedin_profile_url\n    \"\"\"\n    api_key = 'mLyQpIb5enZ32n6pXpUXlg'\n    headers = {'Authorization': 'Bearer ' + api_key}\n    api_endpoint = 'https://nubela.co/proxycurl/api/v2/linkedin'\n    params = {\n        'linkedin_profile_url': linkedin_profile_url,\n        'extra': 'include',\n        'personal_contact_number': 'include',\n        'personal_email': 'include',\n        'inferred_salary': 'include',\n        'skills': 'include',\n        'use_cache': 'if-present',\n        'fallback_to_cache': 'on-error',\n    }\n    response = requests.get(api_endpoint,\n                            params=params,\n                            headers=headers)\n    \n    return json.dumps(response.json())","display_name":"Tool Code","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the dataclass code.","real_time_refresh":true,"refresh_button":true,"title_case":false,"type":"str","_input_type":"MultilineInput"},"tool_description":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"tool_description","value":"get_linkedin_profile_details","display_name":"Description","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the description of the tool.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"tool_function":{"trace_as_metadata":true,"options":["get_linkedin_profile_details"],"combobox":false,"required":true,"placeholder":"","show":true,"name":"tool_function","value":"get_linkedin_profile_details","display_name":"Tool Function","advanced":false,"dynamic":false,"info":"Select the function for additional expressions.","real_time_refresh":true,"refresh_button":true,"title_case":false,"type":"str","_input_type":"DropdownInput","load_from_db":false},"tool_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"tool_name","value":"get_linkedin_profile_details","display_name":"Tool Name","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the name of the tool.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"get_linkedin_profile_details|linkedin_profile_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"get_linkedin_profile_details|linkedin_profile_url","value":"","display_name":"linkedin_profile_url: Description","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the description for linkedin_profile_url","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Tool for linkedin profile data collection","icon":"linkedin","base_classes":["Tool"],"display_name":"Python Code Structured Tool","documentation":"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Tool"],"selected":"Tool","name":"result_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["tool_code","tool_name","tool_description","return_direct","tool_function","global_variables","_classes","_functions"],"beta":false,"edited":true},"id":"PythonCodeStructuredTool-3MIXn"},"selected":false,"width":384,"height":800,"positionAbsolute":{"x":275.89189417312423,"y":1003.9461727226117},"dragging":false},{"id":"ToolCallingAgent-VGNbX","type":"genericNode","position":{"x":2835.8084599835242,"y":681.9875170678375},"data":{"type":"ToolCallingAgent","node":{"template":{"_type":"Component","chat_history":{"trace_as_metadata":true,"list":true,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"chat_history","value":"","display_name":"Chat History","advanced":true,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"llm":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"name":"llm","value":"","display_name":"Language Model","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"tools":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"name":"tools","value":"","display_name":"Tools","advanced":false,"input_types":["Tool","BaseTool"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, List\n\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import HandleInput, DataInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Get best jobs for the user profile\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"handle_parsing_errors":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"handle_parsing_errors","value":true,"display_name":"Handle Parse Errors","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"max_iterations":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_iterations","value":100,"display_name":"Max Iterations","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput","load_from_db":false},"system_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_prompt","value":"","display_name":"System Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System prompt for the agent.","title_case":false,"type":"str","_input_type":"MultilineInput"},"user_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"user_prompt","value":"{input}","display_name":"Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"This prompt must contain 'input' key.","title_case":false,"type":"str","_input_type":"MultilineInput"},"verbose":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"verbose","value":true,"display_name":"Verbose","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Get best jobs for the user profile","icon":"LangChain","base_classes":["AgentExecutor","Message"],"display_name":"Tool Calling Agent","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["AgentExecutor"],"selected":"AgentExecutor","name":"agent","display_name":"Agent","method":"build_agent","value":"__UNDEFINED__","cache":true},{"types":["Message"],"selected":"Message","name":"response","display_name":"Response","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","tools","llm","system_prompt","user_prompt","chat_history"],"beta":true,"edited":true},"id":"ToolCallingAgent-VGNbX"},"selected":false,"width":384,"height":611,"positionAbsolute":{"x":2835.8084599835242,"y":681.9875170678375},"dragging":false},{"id":"Prompt-UjWF7","type":"genericNode","position":{"x":2363.0072725395135,"y":101.36313307727173},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"You are a Internship Job Seeker based on a person resume suggests from at maximum 8 jobs that have most relevance with the user input\n\n1. Use retriever_vector_store FlowTool to Search 8 Jobs for each User that have the similarity, each output of Vector Store have more than 1 job please split it correctly, wait for an output from RetrieverTool. You can invoke retriever_vector_store FlowTool with all information of the user like: summary, headline, etc.. \n2. VERY IMPORTANT Analyze Based on User profile which potential jobs has relation with the student skills and college, like if the user is pursuing a system analysis degree and have technology skills only include jobs that match the most his skills!! For example a Hair Company has no relation with Technology, Data Analysis, etc... Please make your best analysis to avoid include jobs that the user do not have interest or skill.\n3. Execute and Invoke Insert Into Postgresql table  job_infos with the Jobs found for each user, this is the INSERT Statement Example\nINSERT INTO public.job_infos\n(user_id, job_title, company, company_url, job_description, posting_date, job_localization, job_search_time, apply_url)\nVALUES\n(1, 'JOB FOUND1', 'COMPANY NAME', 'https://companyurl', 'description of the job', '2024-01-01', 'SAO PAULO', '2024-09-08 17:00:00', 'https://linkedin.com/xxx'),\n(1, 'JOB FOUND1', 'COMPANY NAME', 'https://companyurl', 'description of the job', '2024-01-01', 'SAO PAULO', '2024-09-08 17:00:00' 'https://linkedin.com/xxx'),\n(1, 'JOB FOUND1', 'COMPANY NAME', 'https://companyurl', 'description of the job', '2024-01-01', 'SAO PAULO', '2024-09-08 17:00:00', 'https://linkedin.com/xxx'),\n(1, 'JOB FOUND1', 'COMPANY NAME', 'https://companyurl', 'description of the job', '2024-01-01', 'SAO PAULO', '2024-09-08 17:00:00' 'https://linkedin.com/xxx'),\n(1, 'JOB FOUND1', 'COMPANY NAME', 'https://companyurl', 'description of the job', '2024-01-01', 'SAO PAULO', '2024-09-08 17:00:00', 'https://linkedin.com/xxx'),\n(2, 'JOB FOUND1', 'COMPANY NAME', 'https://companyurl', 'description of the job', '2024-01-01', 'SAO PAULO', '2024-09-08 17:00:00', 'https://linkedin.com/xxx'),\n(2, 'JOB FOUND1', 'COMPANY NAME', 'https://companyurl', 'description of the job', '2024-01-01', 'SAO PAULO', '2024-09-08 17:00:00', 'https://linkedin.com/xxx'),\nand so on...;\n4. Update Posgresql table with the status Processed! for all users, run this query: (DO NOT INCLUDE ANY WHERE, IT'S A FULL UPDATE!)\nUPDATE public.user_infos\nSET status='Processed!';\n","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput","load_from_db":false}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":[]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-UjWF7","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":326,"positionAbsolute":{"x":2363.0072725395135,"y":101.36313307727173},"dragging":false},{"id":"FlowTool-vFCGt","type":"genericNode","position":{"x":341.70372008335335,"y":46.28207447246342},"data":{"type":"FlowTool","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any, List, Optional\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.base.tools.flow_tool import FlowTool\nfrom langflow.field_typing import Tool\nfrom langflow.graph.graph.base import Graph\nfrom langflow.helpers.flow import get_flow_inputs\nfrom langflow.io import BoolInput, DropdownInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass FlowToolComponent(LCToolComponent):\n    display_name = \"Flow as Tool\"\n    description = \"Construct a Tool from a function that runs the loaded Flow.\"\n    field_order = [\"flow_name\", \"name\", \"description\", \"return_direct\"]\n    trace_type = \"tool\"\n    name = \"FlowTool\"\n    beta = True\n\n    def get_flow_names(self) -> List[str]:\n        flow_datas = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_datas]\n\n    def get_flow(self, flow_name: str) -> Optional[Data]:\n        \"\"\"\n        Retrieves a flow by its name.\n\n        Args:\n            flow_name (str): The name of the flow to retrieve.\n\n        Returns:\n            Optional[Text]: The flow record if found, None otherwise.\n        \"\"\"\n        flow_datas = self.list_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\", display_name=\"Flow Name\", info=\"The name of the flow to run.\", refresh_button=True\n        ),\n        StrInput(\n            name=\"name\",\n            display_name=\"Name\",\n            info=\"The name of the tool.\",\n        ),\n        StrInput(\n            name=\"description\",\n            display_name=\"Description\",\n            info=\"The description of the tool.\",\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Direct\",\n            info=\"Return the result directly from the Tool.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"api_build_tool\", display_name=\"Tool\", method=\"build_tool\"),\n    ]\n\n    def build_tool(self) -> Tool:\n        FlowTool.update_forward_refs()\n        if \"flow_name\" not in self._attributes or not self._attributes[\"flow_name\"]:\n            raise ValueError(\"Flow name is required\")\n        flow_name = self._attributes[\"flow_name\"]\n        flow_data = self.get_flow(flow_name)\n        if not flow_data:\n            raise ValueError(\"Flow not found.\")\n        graph = Graph.from_payload(flow_data.data[\"data\"])\n        inputs = get_flow_inputs(graph)\n        tool = FlowTool(\n            name=self.name,\n            description=self.description,\n            graph=graph,\n            return_direct=self.return_direct,\n            inputs=inputs,\n            flow_id=str(flow_data.id),\n            user_id=str(self.user_id),\n        )\n        description_repr = repr(tool.description).strip(\"'\")\n        args_str = \"\\n\".join([f\"- {arg_name}: {arg_data['description']}\" for arg_name, arg_data in tool.args.items()])\n        self.status = f\"{description_repr}\\nArguments:\\n{args_str}\"\n        return tool  # type: ignore\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"description":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"description","value":"retriever_vector_store","display_name":"Description","advanced":false,"dynamic":false,"info":"The description of the tool.","title_case":false,"type":"str","_input_type":"StrInput"},"flow_name":{"trace_as_metadata":true,"options":["RAG Based LLM","Crewai Flow","Small Document QA","Chain-of-Thought (Auto-CoT) - Prompting Guide","Extra-Context QA","SQLDatabaseFlow","desafio_semana_2_metodo_prompt_dinamico","desafio_semana_2_guilherme_neves","Flow Avaliao RAG","desafio_semana_2_metodo_rag","Complex Agent","Complex Agent (1)","agent_desafio_3","avaliacao_agente_new","agent_desafio_3_last_one","extractor_agent","save_to_vector_store","extractor_loop","jobsearcher_agent","retriever_vector_store"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"flow_name","value":"retriever_vector_store","display_name":"Flow Name","advanced":false,"dynamic":false,"info":"The name of the flow to run.","refresh_button":true,"title_case":false,"type":"str","_input_type":"DropdownInput"},"name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"name","value":"retriever_vector_store","display_name":"Name","advanced":false,"dynamic":false,"info":"The name of the tool.","title_case":false,"type":"str","_input_type":"StrInput"},"return_direct":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"return_direct","value":false,"display_name":"Return Direct","advanced":true,"dynamic":false,"info":"Return the result directly from the Tool.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Construct a Tool from a function that runs the loaded Flow.","base_classes":["Tool"],"display_name":"Flow as Tool","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["flow_name","name","description","return_direct"],"beta":true,"edited":false,"lf_version":"1.0.17"},"id":"FlowTool-vFCGt"},"selected":false,"width":384,"height":498,"positionAbsolute":{"x":341.70372008335335,"y":46.28207447246342},"dragging":false}],"edges":[{"source":"Prompt-z1VCm","target":"ToolCallingAgent-XKkdS","sourceHandle":"{dataType:Prompt,id:Prompt-z1VCm,name:prompt,output_types:[Message]}","targetHandle":"{fieldName:system_prompt,id:ToolCallingAgent-XKkdS,inputTypes:[Message],type:str}","id":"reactflow__edge-Prompt-z1VCm{dataType:Prompt,id:Prompt-z1VCm,name:prompt,output_types:[Message]}-ToolCallingAgent-XKkdS{fieldName:system_prompt,id:ToolCallingAgent-XKkdS,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"system_prompt","id":"ToolCallingAgent-XKkdS","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-z1VCm","name":"prompt","output_types":["Message"]}},"selected":false,"className":""},{"source":"OpenAIModel-Wo0Xn","sourceHandle":"{dataType:OpenAIModel,id:OpenAIModel-Wo0Xn,name:model_output,output_types:[LanguageModel]}","target":"ToolCallingAgent-XKkdS","targetHandle":"{fieldName:llm,id:ToolCallingAgent-XKkdS,inputTypes:[LanguageModel],type:other}","data":{"targetHandle":{"fieldName":"llm","id":"ToolCallingAgent-XKkdS","inputTypes":["LanguageModel"],"type":"other"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-Wo0Xn","name":"model_output","output_types":["LanguageModel"]}},"id":"reactflow__edge-OpenAIModel-Wo0Xn{dataType:OpenAIModel,id:OpenAIModel-Wo0Xn,name:model_output,output_types:[LanguageModel]}-ToolCallingAgent-XKkdS{fieldName:llm,id:ToolCallingAgent-XKkdS,inputTypes:[LanguageModel],type:other}","className":""},{"source":"postgresql_query-Yu6rj","sourceHandle":"{dataType:postgresql_query,id:postgresql_query-Yu6rj,name:api_build_tool,output_types:[Tool]}","target":"ToolCallingAgent-XKkdS","targetHandle":"{fieldName:tools,id:ToolCallingAgent-XKkdS,inputTypes:[Tool,BaseTool],type:other}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-XKkdS","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"postgresql_query","id":"postgresql_query-Yu6rj","name":"api_build_tool","output_types":["Tool"]}},"id":"reactflow__edge-postgresql_query-Yu6rj{dataType:postgresql_query,id:postgresql_query-Yu6rj,name:api_build_tool,output_types:[Tool]}-ToolCallingAgent-XKkdS{fieldName:tools,id:ToolCallingAgent-XKkdS,inputTypes:[Tool,BaseTool],type:other}","className":""},{"source":"ChatInput-PESbG","sourceHandle":"{dataType:ChatInput,id:ChatInput-PESbG,name:message,output_types:[Message]}","target":"ToolCallingAgent-XKkdS","targetHandle":"{fieldName:input_value,id:ToolCallingAgent-XKkdS,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ToolCallingAgent-XKkdS","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatInput","id":"ChatInput-PESbG","name":"message","output_types":["Message"]}},"id":"reactflow__edge-ChatInput-PESbG{dataType:ChatInput,id:ChatInput-PESbG,name:message,output_types:[Message]}-ToolCallingAgent-XKkdS{fieldName:input_value,id:ToolCallingAgent-XKkdS,inputTypes:[Message],type:str}","className":""},{"source":"PythonCodeStructuredTool-3MIXn","sourceHandle":"{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-3MIXn,name:result_tool,output_types:[Tool]}","target":"ToolCallingAgent-XKkdS","targetHandle":"{fieldName:tools,id:ToolCallingAgent-XKkdS,inputTypes:[Tool,BaseTool],type:other}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-XKkdS","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"PythonCodeStructuredTool","id":"PythonCodeStructuredTool-3MIXn","name":"result_tool","output_types":["Tool"]}},"id":"reactflow__edge-PythonCodeStructuredTool-3MIXn{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-3MIXn,name:result_tool,output_types:[Tool]}-ToolCallingAgent-XKkdS{fieldName:tools,id:ToolCallingAgent-XKkdS,inputTypes:[Tool,BaseTool],type:other}","className":""},{"source":"ToolCallingAgent-XKkdS","sourceHandle":"{dataType:ToolCallingAgent,id:ToolCallingAgent-XKkdS,name:response,output_types:[Message]}","target":"ToolCallingAgent-VGNbX","targetHandle":"{fieldName:input_value,id:ToolCallingAgent-VGNbX,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ToolCallingAgent-VGNbX","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ToolCallingAgent","id":"ToolCallingAgent-XKkdS","name":"response","output_types":["Message"]}},"id":"reactflow__edge-ToolCallingAgent-XKkdS{dataType:ToolCallingAgent,id:ToolCallingAgent-XKkdS,name:response,output_types:[Message]}-ToolCallingAgent-VGNbX{fieldName:input_value,id:ToolCallingAgent-VGNbX,inputTypes:[Message],type:str}","className":"","selected":false},{"source":"postgresql_query-Yu6rj","sourceHandle":"{dataType:postgresql_query,id:postgresql_query-Yu6rj,name:api_build_tool,output_types:[Tool]}","target":"ToolCallingAgent-VGNbX","targetHandle":"{fieldName:tools,id:ToolCallingAgent-VGNbX,inputTypes:[Tool,BaseTool],type:other}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-VGNbX","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"postgresql_query","id":"postgresql_query-Yu6rj","name":"api_build_tool","output_types":["Tool"]}},"id":"reactflow__edge-postgresql_query-Yu6rj{dataType:postgresql_query,id:postgresql_query-Yu6rj,name:api_build_tool,output_types:[Tool]}-ToolCallingAgent-VGNbX{fieldName:tools,id:ToolCallingAgent-VGNbX,inputTypes:[Tool,BaseTool],type:other}","className":"","selected":false},{"source":"Prompt-UjWF7","sourceHandle":"{dataType:Prompt,id:Prompt-UjWF7,name:prompt,output_types:[Message]}","target":"ToolCallingAgent-VGNbX","targetHandle":"{fieldName:system_prompt,id:ToolCallingAgent-VGNbX,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"system_prompt","id":"ToolCallingAgent-VGNbX","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-UjWF7","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-UjWF7{dataType:Prompt,id:Prompt-UjWF7,name:prompt,output_types:[Message]}-ToolCallingAgent-VGNbX{fieldName:system_prompt,id:ToolCallingAgent-VGNbX,inputTypes:[Message],type:str}","className":""},{"source":"OpenAIModel-Wo0Xn","sourceHandle":"{dataType:OpenAIModel,id:OpenAIModel-Wo0Xn,name:model_output,output_types:[LanguageModel]}","target":"ToolCallingAgent-VGNbX","targetHandle":"{fieldName:llm,id:ToolCallingAgent-VGNbX,inputTypes:[LanguageModel],type:other}","data":{"targetHandle":{"fieldName":"llm","id":"ToolCallingAgent-VGNbX","inputTypes":["LanguageModel"],"type":"other"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-Wo0Xn","name":"model_output","output_types":["LanguageModel"]}},"id":"reactflow__edge-OpenAIModel-Wo0Xn{dataType:OpenAIModel,id:OpenAIModel-Wo0Xn,name:model_output,output_types:[LanguageModel]}-ToolCallingAgent-VGNbX{fieldName:llm,id:ToolCallingAgent-VGNbX,inputTypes:[LanguageModel],type:other}","className":""},{"source":"FlowTool-vFCGt","sourceHandle":"{dataType:FlowTool,id:FlowTool-vFCGt,name:api_build_tool,output_types:[Tool]}","target":"ToolCallingAgent-VGNbX","targetHandle":"{fieldName:tools,id:ToolCallingAgent-VGNbX,inputTypes:[Tool,BaseTool],type:other}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-VGNbX","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"FlowTool","id":"FlowTool-vFCGt","name":"api_build_tool","output_types":["Tool"]}},"id":"reactflow__edge-FlowTool-vFCGt{dataType:FlowTool,id:FlowTool-vFCGt,name:api_build_tool,output_types:[Tool]}-ToolCallingAgent-VGNbX{fieldName:tools,id:ToolCallingAgent-VGNbX,inputTypes:[Tool,BaseTool],type:other}","className":""}],"viewport":{"x":340.29017201308125,"y":-101.98283094316685,"zoom":0.6085597243300254}},"description":"jobsearcher agent","name":"jobsearcher_agent","last_tested_version":"1.0.17","endpoint_name":null,"is_component":false}