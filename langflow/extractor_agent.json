{"id":"58b2c686-a685-4308-a840-f6a098b73123","data":{"nodes":[{"id":"ToolCallingAgent-D6Y48","type":"genericNode","position":{"x":1722.8068080976375,"y":333.35584918323866},"data":{"type":"ToolCallingAgent","node":{"template":{"_type":"Component","chat_history":{"trace_as_input":true,"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"chat_history","display_name":"Chat History","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"llm":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"value":"","name":"llm","display_name":"Language Model","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"tools":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"tools","display_name":"Tools","advanced":false,"input_types":["Tool","BaseTool"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, List\n\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import HandleInput, DataInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"handle_parsing_errors":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"handle_parsing_errors","display_name":"Handle Parse Errors","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"max_iterations":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":20,"name":"max_iterations","display_name":"Max Iterations","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"system_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_prompt","display_name":"System Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System prompt for the agent.","title_case":false,"type":"str","_input_type":"MultilineInput"},"user_prompt":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{input}","name":"user_prompt","display_name":"Prompt","advanced":true,"input_types":["Message"],"dynamic":false,"info":"This prompt must contain 'input' key.","title_case":false,"type":"str","_input_type":"MultilineInput"},"verbose":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"verbose","display_name":"Verbose","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Agent that uses tools","icon":"LangChain","base_classes":["AgentExecutor","Message"],"display_name":"Tool Calling Agent","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["AgentExecutor"],"selected":"AgentExecutor","name":"agent","display_name":"Agent","method":"build_agent","value":"__UNDEFINED__","cache":true,"hidden":false},{"types":["Message"],"selected":"Message","name":"response","display_name":"Response","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","tools","llm","system_prompt","user_prompt","chat_history"],"beta":true,"edited":false,"lf_version":"1.0.17"},"id":"ToolCallingAgent-D6Y48"},"selected":false,"width":384,"height":659,"dragging":false,"positionAbsolute":{"x":1722.8068080976375,"y":333.35584918323866}},{"id":"ChatInput-TkGod","type":"genericNode","position":{"x":24.991273452964776,"y":332.687230039787},"data":{"type":"ChatInput","node":{"template":{"_type":"Component","files":{"trace_as_metadata":true,"file_path":"","fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx","jpg","jpeg","png","bmp","image"],"list":true,"required":false,"placeholder":"","show":true,"name":"files","value":"","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","title_case":false,"type":"file","_input_type":"FileInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\nfrom time import sleep\nfrom random import random\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n    \n        self.status = message\n        wait_api = round(random() * 10)\n        print(f\"WAITING {wait_api} SECONDS. BEFORE API CALLS!\")\n        sleep(wait_api)\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"make an invoke to send actor_id BHzefUZlZRKWxkTck limit 3 offset 0 to FlowTool. another invoke to Tool FlowTool with chat_input being a dynamic value, NOT WHAT I'M TYPING HERE, it's needs to be the output of the APIRUNFY summarized.\nADD METADATA TO EACH JOB LIKE: TECHNOLOGY, ENGINEERING, FINANCE, ADMINISTRATION, MARKETING, ETC... EVERYTHING IS INTERNSHIP","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"sender","value":"User","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str","_input_type":"DropdownInput"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sender_name","value":"User","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"session_id","value":"","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"should_store_message":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"should_store_message","value":true,"display_name":"Store Messages","advanced":true,"dynamic":false,"info":"Store the message in the history.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message"],"display_name":"Chat Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","should_store_message","sender","sender_name","session_id","files"],"beta":false,"edited":true,"lf_version":"1.0.17"},"id":"ChatInput-TkGod"},"selected":false,"width":384,"height":298,"dragging":false,"positionAbsolute":{"x":24.991273452964776,"y":332.687230039787}},{"id":"Prompt-plITe","type":"genericNode","position":{"x":1016.4948319871553,"y":27.925311855437286},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"Your Job is to Invoking: `FlowTool`\n","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput","load_from_db":false}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":[]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false,"lf_version":"1.0.17"},"id":"Prompt-plITe","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":326,"dragging":false,"positionAbsolute":{"x":1016.4948319871553,"y":27.925311855437286}},{"id":"ComposioAPI-pX3eO","type":"genericNode","position":{"x":248.39970785849323,"y":-431.73360991875313},"data":{"type":"ComposioAPI","node":{"template":{"_type":"Component","action_names":{"trace_as_metadata":true,"options":["FIRECRAWL_CHECK_CRAWL_STATUS","FIRECRAWL_CRAWL","FIRECRAWL_EXTRACT","FIRECRAWL_SCRAPE","FIRECRAWL_SEARCH"],"combobox":false,"list":true,"required":false,"placeholder":"","show":true,"name":"action_names","value":["FIRECRAWL_SCRAPE"],"display_name":"Actions to use","advanced":false,"dynamic":false,"info":"The actions to pass to agent to execute","title_case":false,"type":"str","_input_type":"MultiselectInput","load_from_db":false},"api_key":{"load_from_db":false,"required":true,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"Composio API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Refer to https://docs.composio.dev/introduction/foundations/howtos/get_api_key","refresh_button":true,"title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"app_names":{"trace_as_metadata":true,"options":["APIFY_CONNECTED","FIRECRAWL_CONNECTED","GITHUB_CONNECTED","SERPAPI_CONNECTED","APALEO","ASANA","ATTIO","BITBUCKET","BREVO","BROWSERBASE_TOOL","BROWSER_TOOL","CLICKUP","CODEINTERPRETER","CODE_FORMAT_TOOL","CODE_GREP_TOOL","CODE_INDEX_TOOL","CODE_MAP_TOOL","COMPOSIO","DISCORD","DROPBOX","ELEVENLABS","EMBED_TOOL","EXA","FIGMA","FILETOOL","GIT","GITLAB","GMAIL","GOOGLECALENDAR","GOOGLEDOCS","GOOGLEDRIVE","GOOGLEMEET","GOOGLESHEETS","GOOGLETASKS","GREPTILE","HACKERNEWS","HEROKU","HISTORY_FETCHER","HUBSPOT","IMAGE_ANALYSER","INDUCED_AI","JIRA","KLAVIYO","LINEAR","LISTENNOTES","MATHEMATICAL","MULTIONAI","NASA","NOTION","OKTA","PAGERDUTY","PERPLEXITYAI","PIPEDRIVE","POSTHOG","RAGTOOL","SCHEDULER","SHELLTOOL","SLACK","SLACKBOT","SNOWFLAKE","SOUNDCLOUD","SPIDERTOOL","SPLITWISE","SPOTIFY","SQLTOOL","STRAVA","TASKADE","TAVILY","TRELLO","TWILIO","TWITTER","TYPEFORM","WEATHERMAP","WEBTOOL","WHATSAPP","WORKABLE","WORKSPACE_TOOL","YOUSEARCH","YOUTUBE","ZENDESK","ZEPTOOL","ZOOM"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"app_names","value":"FIRECRAWL_CONNECTED","display_name":"App Name","advanced":false,"dynamic":false,"info":"The app name to use. Please refresh after selecting app name","refresh_button":true,"title_case":false,"type":"str","_input_type":"DropdownInput","load_from_db":false},"auth_status_config":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"auth_status_config","value":"FIRECRAWL CONNECTED","display_name":"Auth status","advanced":false,"dynamic":false,"info":"Open link or enter api key. Then refresh button","refresh_button":true,"title_case":false,"type":"str","_input_type":"StrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any, Sequence\n\nfrom composio_langchain import Action, App, ComposioToolSet  # type: ignore\nfrom langchain_core.tools import Tool\nfrom loguru import logger\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.inputs import DropdownInput, MessageTextInput, MultiselectInput, SecretStrInput, StrInput\n\n\nclass ComposioAPIComponent(LCToolComponent):\n    display_name: str = \"Composio Tools\"\n    description: str = \"Use Composio toolset to run actions with your agent\"\n    name = \"ComposioAPI\"\n    icon = \"Composio\"\n    documentation: str = \"https://docs.composio.dev\"\n\n    inputs = [\n        MessageTextInput(name=\"entity_id\", display_name=\"Entity ID\", value=\"default\", advanced=True),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Composio API Key\",\n            required=True,\n            refresh_button=True,\n            info=\"Refer to https://docs.composio.dev/introduction/foundations/howtos/get_api_key\",\n        ),\n        DropdownInput(\n            name=\"app_names\",\n            display_name=\"App Name\",\n            options=[app_name for app_name in App.__annotations__],\n            value=\"\",\n            info=\"The app name to use. Please refresh after selecting app name\",\n            refresh_button=True,\n        ),\n        MultiselectInput(\n            name=\"action_names\",\n            display_name=\"Actions to use\",\n            required=False,\n            options=[],\n            value=[],\n            info=\"The actions to pass to agent to execute\",\n        ),\n        StrInput(\n            name=\"auth_status_config\",\n            display_name=\"Auth status\",\n            value=\"\",\n            refresh_button=True,\n            info=\"Open link or enter api key. Then refresh button\",\n        ),\n    ]\n\n    def _check_for_authorization(self, app: str) -> str:\n        \"\"\"\n        Checks if the app is authorized.\n\n        Args:\n            app (str): The app name to check authorization for.\n\n        Returns:\n            str: The authorization status.\n        \"\"\"\n        toolset = self._build_wrapper()\n        entity = toolset.client.get_entity(id=self.entity_id)\n        try:\n            entity.get_connection(app=app)\n            return f\"{app} CONNECTED\"\n        except Exception:\n            return self._handle_authorization_failure(toolset, entity, app)\n\n    def _handle_authorization_failure(self, toolset: ComposioToolSet, entity: Any, app: str) -> str:\n        \"\"\"\n        Handles the authorization failure by attempting to process API key auth or initiate default connection.\n\n        Args:\n            toolset (ComposioToolSet): The toolset instance.\n            entity (Any): The entity instance.\n            app (str): The app name.\n\n        Returns:\n            str: The result of the authorization failure message.\n        \"\"\"\n        try:\n            auth_schemes = toolset.client.apps.get(app).auth_schemes\n            if auth_schemes[0].auth_mode == \"API_KEY\":\n                return self._process_api_key_auth(entity, app)\n            else:\n                return self._initiate_default_connection(entity, app)\n        except Exception as exc:\n            logger.error(f\"Authorization error: {str(exc)}\")\n            return \"Error\"\n\n    def _process_api_key_auth(self, entity: Any, app: str) -> str:\n        \"\"\"\n        Processes the API key authentication.\n\n        Args:\n            entity (Any): The entity instance.\n            app (str): The app name.\n\n        Returns:\n            str: The status of the API key authentication.\n        \"\"\"\n        auth_status_config = self.auth_status_config\n        is_url = \"http\" in auth_status_config or \"https\" in auth_status_config\n        is_different_app = \"CONNECTED\" in auth_status_config and app not in auth_status_config\n        is_default_api_key_message = \"API Key\" in auth_status_config\n\n        if is_different_app or is_url or is_default_api_key_message:\n            return \"Enter API Key\"\n        else:\n            if not is_default_api_key_message:\n                entity.initiate_connection(\n                    app_name=app,\n                    auth_mode=\"API_KEY\",\n                    auth_config={\"api_key\": self.auth_status_config},\n                    use_composio_auth=False,\n                    force_new_integration=True,\n                )\n                return f\"{app} CONNECTED\"\n            else:\n                return \"Enter API Key\"\n\n    def _initiate_default_connection(self, entity: Any, app: str) -> str:\n        connection = entity.initiate_connection(app_name=app, use_composio_auth=True, force_new_integration=True)\n        return connection.redirectUrl\n\n    def _get_connected_app_names_for_entity(self) -> list[str]:\n        toolset = self._build_wrapper()\n        connections = toolset.client.get_entity(id=self.entity_id).get_connections()\n        return list(set(connection.appUniqueId for connection in connections))\n\n    def _update_app_names_with_connected_status(self, build_config: dict) -> dict:\n        connected_app_names = self._get_connected_app_names_for_entity()\n\n        app_names = [\n            f\"{app_name}_CONNECTED\" for app_name in App.__annotations__ if app_name.lower() in connected_app_names\n        ]\n        non_connected_app_names = [\n            app_name for app_name in App.__annotations__ if app_name.lower() not in connected_app_names\n        ]\n        build_config[\"app_names\"][\"options\"] = app_names + non_connected_app_names\n        build_config[\"app_names\"][\"value\"] = app_names[0] if app_names else \"\"\n        return build_config\n\n    def _get_normalized_app_name(self) -> str:\n        return self.app_names.replace(\"_CONNECTED\", \"\").replace(\"_connected\", \"\")\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name == \"api_key\":\n            if hasattr(self, \"api_key\") and self.api_key != \"\":\n                build_config = self._update_app_names_with_connected_status(build_config)\n            return build_config\n\n        if field_name in {\"app_names\", \"auth_status_config\"}:\n            if hasattr(self, \"api_key\") and self.api_key != \"\":\n                build_config[\"auth_status_config\"][\"value\"] = self._check_for_authorization(\n                    self._get_normalized_app_name()\n                )\n            all_action_names = [action_name for action_name in Action.__annotations__]\n            app_action_names = [\n                action_name\n                for action_name in all_action_names\n                if action_name.lower().startswith(self._get_normalized_app_name().lower() + \"_\")\n            ]\n            build_config[\"action_names\"][\"options\"] = app_action_names\n            build_config[\"action_names\"][\"value\"] = [app_action_names[0]] if app_action_names else [\"\"]\n        return build_config\n\n    def build_tool(self) -> Sequence[Tool]:\n        composio_toolset = self._build_wrapper()\n        composio_tools = composio_toolset.get_actions(actions=self.action_names)\n        return composio_tools\n\n    def _build_wrapper(self) -> ComposioToolSet:\n        return ComposioToolSet(api_key=self.api_key)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"entity_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"entity_id","value":"default","display_name":"Entity ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Use Composio toolset to run actions with your agent","icon":"Composio","base_classes":["Data","Tool"],"display_name":"Composio Tools","documentation":"https://docs.composio.dev","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"api_run_model","display_name":"Data","method":"run_model","value":"__UNDEFINED__","cache":true},{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["entity_id","api_key","app_names","action_names","auth_status_config"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"ComposioAPI-pX3eO","description":"Use Composio toolset to run actions with your agent","display_name":"Composio Tools"},"selected":false,"width":384,"height":629,"positionAbsolute":{"x":248.39970785849323,"y":-431.73360991875313},"dragging":false},{"id":"OpenAIModel-fQny2","type":"genericNode","position":{"x":868.0762370508578,"y":1008.5138163688032},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"json_mode","value":false,"display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gpt-4o-mini","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"output_schema","value":{},"display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"seed","value":1,"display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"OpenAIModel-fQny2","description":"Generates text using OpenAI LLMs.","display_name":"OpenAI"},"selected":false,"width":384,"height":601,"positionAbsolute":{"x":868.0762370508578,"y":1008.5138163688032},"dragging":false},{"id":"PythonCodeStructuredTool-dJ7OJ","type":"genericNode","position":{"x":-627.0534679926088,"y":78.06328015347341},"data":{"type":"PythonCodeStructuredTool","node":{"template":{"_type":"Component","_classes":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"_classes","value":"[]","display_name":"Classes","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"_functions":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"_functions","value":"{\"fetch_data\": {\"name\": \"fetch_data\", \"args\": [{\"name\": \"limit\", \"annotation\": null}, {\"name\": \"offset\", \"annotation\": null}, {\"name\": \"actor_id\", \"annotation\": null}]}}","display_name":"Functions","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"ğŸ\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"global_variables":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"name":"global_variables","value":"","display_name":"Global Variables","advanced":false,"input_types":["Data"],"dynamic":false,"info":"Enter the global variables or Create Data Component.","title_case":false,"type":"dict","_input_type":"HandleInput"},"return_direct":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"return_direct","value":true,"display_name":"Return Directly","advanced":false,"dynamic":false,"info":"Should the tool return the function output directly?","title_case":false,"type":"bool","_input_type":"BoolInput"},"tool_code":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"def my_function(args):\n    pass","show":true,"name":"tool_code","value":"from apify_client import ApifyClient\nimport json\n\n# Define limit , initial offset and actor_id\nlimit = 3\noffset = 0\nactor_id=''\n\ndef fetch_data(limit, offset, actor_id):\n    try:\n        client = ApifyClient('apify_api_HY22N0bHDHJidiCECEGx9dFZ3DapLv0e06V3')\n        run_details = client.actor(actor_id).last_run().get()\n        dataset_id = run_details['defaultDatasetId']\n        dataset_items = client.dataset(dataset_id).list_items(offset=offset, limit=limit).items\n\n        return json.dumps(dataset_items)\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return []\n","display_name":"Tool Code","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the dataclass code.","real_time_refresh":true,"refresh_button":true,"title_case":false,"type":"str","_input_type":"MultilineInput"},"tool_description":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"tool_description","value":"Get APIFY Data Run using filters","display_name":"Description","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the description of the tool.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"tool_function":{"trace_as_metadata":true,"options":["fetch_data"],"combobox":false,"required":true,"placeholder":"","show":true,"name":"tool_function","value":"fetch_data","display_name":"Tool Function","advanced":false,"dynamic":false,"info":"Select the function for additional expressions.","real_time_refresh":true,"refresh_button":true,"title_case":false,"type":"str","_input_type":"DropdownInput"},"tool_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"tool_name","value":"GetAPIFYRun","display_name":"Tool Name","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the name of the tool.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"fetch_data|limit":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"fetch_data|limit","value":"Limit of returned items","display_name":"limit: Description","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the description for limit","title_case":false,"type":"str","_input_type":"MessageTextInput"},"fetch_data|offset":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"fetch_data|offset","value":"Initial position of the list","display_name":"offset: Description","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the description for offset","title_case":false,"type":"str","_input_type":"MessageTextInput"},"fetch_data|actor_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"fetch_data|actor_id","value":"actor_id","display_name":"actor_id: Description","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the description for actor_id","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"structuredtool dataclass code to tool","icon":"ğŸ","base_classes":["Tool"],"display_name":"Python Code Structured Tool","documentation":"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Tool"],"selected":"Tool","name":"result_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["tool_code","tool_name","tool_description","return_direct","tool_function","global_variables","_classes","_functions"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"PythonCodeStructuredTool-dJ7OJ"},"selected":false,"width":384,"height":968,"positionAbsolute":{"x":-627.0534679926088,"y":78.06328015347341},"dragging":false},{"id":"FlowTool-Z52aY","type":"genericNode","position":{"x":152.18230703655024,"y":739.1290081861247},"data":{"type":"FlowTool","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any, List, Optional\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.base.tools.flow_tool import FlowTool\nfrom langflow.field_typing import Tool\nfrom langflow.graph.graph.base import Graph\nfrom langflow.helpers.flow import get_flow_inputs\nfrom langflow.io import BoolInput, DropdownInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass FlowToolComponent(LCToolComponent):\n    display_name = \"Flow as Tool\"\n    description = \"Construct a Tool from a function that runs the loaded Flow.\"\n    field_order = [\"flow_name\", \"name\", \"description\", \"return_direct\"]\n    trace_type = \"tool\"\n    name = \"FlowTool\"\n    beta = True\n\n    def get_flow_names(self) -> List[str]:\n        flow_datas = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_datas]\n\n    def get_flow(self, flow_name: str) -> Optional[Data]:\n        \"\"\"\n        Retrieves a flow by its name.\n\n        Args:\n            flow_name (str): The name of the flow to retrieve.\n\n        Returns:\n            Optional[Text]: The flow record if found, None otherwise.\n        \"\"\"\n        flow_datas = self.list_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\", display_name=\"Flow Name\", info=\"The name of the flow to run.\", refresh_button=True\n        ),\n        StrInput(\n            name=\"name\",\n            display_name=\"Name\",\n            info=\"The name of the tool.\",\n        ),\n        StrInput(\n            name=\"description\",\n            display_name=\"Description\",\n            info=\"The description of the tool.\",\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Direct\",\n            info=\"Return the result directly from the Tool.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"api_build_tool\", display_name=\"Tool\", method=\"build_tool\"),\n    ]\n\n    def build_tool(self) -> Tool:\n        FlowTool.update_forward_refs()\n        if \"flow_name\" not in self._attributes or not self._attributes[\"flow_name\"]:\n            raise ValueError(\"Flow name is required\")\n        flow_name = self._attributes[\"flow_name\"]\n        flow_data = self.get_flow(flow_name)\n        if not flow_data:\n            raise ValueError(\"Flow not found.\")\n        graph = Graph.from_payload(flow_data.data[\"data\"])\n        inputs = get_flow_inputs(graph)\n        tool = FlowTool(\n            name=self.name,\n            description=self.description,\n            graph=graph,\n            return_direct=self.return_direct,\n            inputs=inputs,\n            flow_id=str(flow_data.id),\n            user_id=str(self.user_id),\n        )\n        description_repr = repr(tool.description).strip(\"'\")\n        args_str = \"\\n\".join([f\"- {arg_name}: {arg_data['description']}\" for arg_name, arg_data in tool.args.items()])\n        self.status = f\"{description_repr}\\nArguments:\\n{args_str}\"\n        return tool  # type: ignore\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"description":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"description","value":"","display_name":"Description","advanced":false,"dynamic":false,"info":"The description of the tool.","title_case":false,"type":"str","_input_type":"StrInput"},"flow_name":{"trace_as_metadata":true,"options":["RAG Based LLM","Crewai Flow","Small Document QA","Chain-of-Thought (Auto-CoT) - Prompting Guide","Extra-Context QA","SQLDatabaseFlow","desafio_semana_2_metodo_prompt_dinamico","desafio_semana_2_guilherme_neves","Flow AvaliaÃ§Ã£o RAG","desafio_semana_2_metodo_rag","Complex Agent","Complex Agent (1)","agent_desafio_3","avaliacao_agente_new","agent_desafio_3_last_one","extractor_agent","save_to_vector_store","extractor_loop","jobsearcher_agent"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"flow_name","value":"save_to_vector_store","display_name":"Flow Name","advanced":false,"dynamic":false,"info":"The name of the flow to run.","refresh_button":true,"title_case":false,"type":"str","_input_type":"DropdownInput","load_from_db":false},"name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"name","value":"save_to_vector_store","display_name":"Name","advanced":false,"dynamic":false,"info":"The name of the tool.","title_case":false,"type":"str","_input_type":"StrInput"},"return_direct":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"return_direct","value":false,"display_name":"Return Direct","advanced":true,"dynamic":false,"info":"Return the result directly from the Tool.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Construct a Tool from a function that runs the loaded Flow.","base_classes":["Tool"],"display_name":"Flow as Tool","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["flow_name","name","description","return_direct"],"beta":true,"edited":false},"id":"FlowTool-Z52aY"},"selected":true,"width":384,"height":500,"positionAbsolute":{"x":152.18230703655024,"y":739.1290081861247},"dragging":false}],"edges":[{"source":"Prompt-plITe","target":"ToolCallingAgent-D6Y48","sourceHandle":"{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-plITeÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}","targetHandle":"{Å“fieldNameÅ“:Å“system_promptÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}","id":"reactflow__edge-Prompt-plITe{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-plITeÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ToolCallingAgent-D6Y48{Å“fieldNameÅ“:Å“system_promptÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}","data":{"targetHandle":{"fieldName":"system_prompt","id":"ToolCallingAgent-D6Y48","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-plITe","name":"prompt","output_types":["Message"]}},"selected":false,"className":""},{"source":"OpenAIModel-fQny2","sourceHandle":"{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-fQny2Å“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}","target":"ToolCallingAgent-D6Y48","targetHandle":"{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“LanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}","data":{"targetHandle":{"fieldName":"llm","id":"ToolCallingAgent-D6Y48","inputTypes":["LanguageModel"],"type":"other"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-fQny2","name":"model_output","output_types":["LanguageModel"]}},"id":"reactflow__edge-OpenAIModel-fQny2{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-fQny2Å“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}-ToolCallingAgent-D6Y48{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“LanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}","className":""},{"source":"ComposioAPI-pX3eO","sourceHandle":"{Å“dataTypeÅ“:Å“ComposioAPIÅ“,Å“idÅ“:Å“ComposioAPI-pX3eOÅ“,Å“nameÅ“:Å“api_build_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}","target":"ToolCallingAgent-D6Y48","targetHandle":"{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-D6Y48","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"ComposioAPI","id":"ComposioAPI-pX3eO","name":"api_build_tool","output_types":["Tool"]}},"id":"reactflow__edge-ComposioAPI-pX3eO{Å“dataTypeÅ“:Å“ComposioAPIÅ“,Å“idÅ“:Å“ComposioAPI-pX3eOÅ“,Å“nameÅ“:Å“api_build_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}-ToolCallingAgent-D6Y48{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}","className":""},{"source":"PythonCodeStructuredTool-dJ7OJ","sourceHandle":"{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-dJ7OJÅ“,Å“nameÅ“:Å“result_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}","target":"ToolCallingAgent-D6Y48","targetHandle":"{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-D6Y48","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"PythonCodeStructuredTool","id":"PythonCodeStructuredTool-dJ7OJ","name":"result_tool","output_types":["Tool"]}},"id":"reactflow__edge-PythonCodeStructuredTool-dJ7OJ{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-dJ7OJÅ“,Å“nameÅ“:Å“result_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}-ToolCallingAgent-D6Y48{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}","className":"","selected":false},{"source":"FlowTool-Z52aY","sourceHandle":"{Å“dataTypeÅ“:Å“FlowToolÅ“,Å“idÅ“:Å“FlowTool-Z52aYÅ“,Å“nameÅ“:Å“api_build_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}","target":"ToolCallingAgent-D6Y48","targetHandle":"{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}","data":{"targetHandle":{"fieldName":"tools","id":"ToolCallingAgent-D6Y48","inputTypes":["Tool","BaseTool"],"type":"other"},"sourceHandle":{"dataType":"FlowTool","id":"FlowTool-Z52aY","name":"api_build_tool","output_types":["Tool"]}},"id":"reactflow__edge-FlowTool-Z52aY{Å“dataTypeÅ“:Å“FlowToolÅ“,Å“idÅ“:Å“FlowTool-Z52aYÅ“,Å“nameÅ“:Å“api_build_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}-ToolCallingAgent-D6Y48{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}","className":"","selected":false},{"source":"ChatInput-TkGod","sourceHandle":"{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-TkGodÅ“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}","target":"ToolCallingAgent-D6Y48","targetHandle":"{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}","data":{"targetHandle":{"fieldName":"input_value","id":"ToolCallingAgent-D6Y48","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatInput","id":"ChatInput-TkGod","name":"message","output_types":["Message"]}},"id":"reactflow__edge-ChatInput-TkGod{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-TkGodÅ“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ToolCallingAgent-D6Y48{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ToolCallingAgent-D6Y48Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}","className":""}],"viewport":{"x":221.00581312723898,"y":254.8147300380868,"zoom":0.5904823439490289}},"description":"extractor agent","name":"extractor_agent","last_tested_version":"1.0.17","endpoint_name":null,"is_component":false}